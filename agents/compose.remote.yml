services:
  tiny-agent:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - 6060:8000
    environment:
      - PORT=8000
      - OPENAI_API_BASE=${DMR_BASE_URL}/engines/llama.cpp/v1
      - OPENAI_API_KEY="tinymodelsaretheway"
      - MODEL_RUNNER_CHAT_MODEL=${MODEL_RUNNER_CHAT_MODEL}
    depends_on:
      - download-chat-model
      
  download-chat-model:
    image: curlimages/curl:8.12.1
    entrypoint: |
      sh -c '
      # Download Chat model
      curl -s "${DMR_BASE_URL}/models/create" -d @- << EOF
      {"from": "${MODEL_RUNNER_CHAT_MODEL}"}
      EOF
      '
